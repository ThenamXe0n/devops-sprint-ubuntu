# Install Docker & Docker Compose the Right Way (on Ubuntu)
From here on, everything we deploy (Node, MongoDB, Nginx, Next.js, CI/CD) will run inside Docker containers.

So this step is about:

âœ” Installing Docker
âœ” Installing Docker Compose (plugin method â€” industry-preferred)
âœ” Making Docker usable without sudo
âœ” Verifying everything works

And of course â€” Iâ€™ll explain the WHY behind each part.
---
> ðŸ§  Why Docker? (Short but deep)

Without Docker:
- Each app needs its own Node version
- Dependencies pollute the server
- â€œWorks on my machineâ€ becomes a nightmare
- Deploying updates risks breaking existing apps

With Docker:

- Each app runs in its own isolated box (container)
- Same environment everywhere â€” laptop â†’ staging â†’ production
- Rolling updates become easy
- Reproducibility & portability increase dramatically
This is exactly how modern companies run apps.
---

> # -A â€” Uninstall any old Docker versions (safeguard)
```
sudo apt remove docker docker-engine docker.io containerd runc
```
### B â€” Update your package list
```
sudo apt update
```
This ensures your system knows about the latest package versions.

### -C â€” Install required dependencies
These packages allow apt to use HTTPS repos securely:
```
sudo apt install -y ca-certificates curl gnupg
```
### -D â€” Add Dockerâ€™s official GPG key
This proves packages really come from Docker and not a fake source.
```

sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
sudo chmod a+r /etc/apt/keyrings/docker.gpg
```
---
### -E â€” Add the Docker Repository
```
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
```
now your server knows where to get official Docker build 
---

### -F â€” Update again
```
sudo spt update
```
### -G â€” Install Docker Engine + CLI + Containerd + Compose Plugin
```
sudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
```

---
This installs:
- docker-ce â†’ The Docker engine
- docker-cli â†’ Command tool
- containerd â†’ Runtime
- buildx â†’ Advanced builds
- compose-plugin â†’ Modern Docker Compose

> ðŸ§  Note: The old docker-compose Python version is deprecated.
Professionals now use the Compose plugin â†’ docker compose (space, not dash).

---
### -H â€” Verify Docker Works
```
sudo docker run hello-world
```
Expected output:
Docker pulls a tiny test container and prints a success message ðŸŽ‰

> note : This is security-critical.

---
### -I â€” Allow your user to run Docker WITHOUT sudo
```
sudo usermod -aG docker $USER
```
now log out and log back in: 
```
exit
```

---
### -J â€” Verify Docker Compose
```
Docker Compose version V2.x.x
```
This confirms the plugin version is installed â€” modern & supported
---

### How Industry Engineers Install Docker
You just followed the official and recommended method.
Alternatives used in real life:

---
### ðŸ›¡ Security Notes (Important But Simple)

Docker group members can control the Docker daemon â€” meaning they effectively have root-like power.

This is normal & expected in DevOps.

Companies control access using:

- âœ” IAM
- âœ” SSH keys
- âœ” VPN / Bastion
- âœ” Audit logs

So donâ€™t casually add random users to the docker group.
---

### ðŸŽ¯ At the End of Step 4 â€” You Will Have:

âœ” Docker installed
âœ” Docker Compose installed
âœ” Non-root Docker usage
âœ” Test containers running
âœ” Clean, secure setup

This is the foundation of your deployment pipeline.

> Next steps after this will be:

âž¡ï¸ Step 5 â€” Install Node (for local builds & debugging only)
âž¡ï¸ Step 6 â€” Setup NGINX reverse proxy (production-grade)
âž¡ï¸ Step 7 â€” Structure your MERN + Next.js apps for Docker
âž¡ï¸ Step 8 â€” Docker Compose for multi-service apps
âž¡ï¸ Step 9 â€” CI/CD (GitHub Actions â†’ server deploy)

All step-by-step with deep explanations â€” no rushing.

---
# Install Node.js (for optional local debugging & utility use â€” NOT for production runtime, since Docker handles that)

### -A â€” Add NodeSource Repo
```
curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
```
This script:

- âœ” Securely adds the NodeSource signing key
- âœ” Adds the apt repository
- âœ” Prepares your system for Node.js 20 LTS

> ðŸ§  Why Node 20?
  Because it is LTS â€” Long Term Support, which is what production environments use.

### -B â€” Install Node.js
```
sudo apt install -y nodejs
```
This installs:

âœ” node â€” the runtime
âœ” npm â€” package manager 



